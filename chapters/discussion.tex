\chapter{Discussion}


The previous sample sessions in the results section showed the ability of the earthEngineGrabR to acquire remote sensing data for various research questions.
Compared to the standard approach described in the introduction the earthEngineGrabR is superior in various ways:
The use of the earthEngineGrabR to acquire remote sensing data for a specific time, region and aggregation provide significant savings of time, processing resources and labour. To acquire, the data for the illustrated use-cases was a matter of minutes, even the aggregation of daily precipitation satellite imagery for 15 years required less than 15 m. The necessary processing resources for the computation was outsourced entirely, while there was only a minimum of load on the local processing resources. Further, no manual preprocessing or integration of different data sources was necessary, and no external GIS software had to be used. The entire process could be controlled from within R, and only a minimum of GIS knowledge and no experience with Python or the EE Python API was required. With the earthEngineGrabR, the user not only could harvest data products from the earth engine data catalogue but with the aggregation process controlled by the user, could generate new data dependent on the research questions. 

Therefore, for the described use cases, I can say that the earthEngineGrabR strongly simplified and at the same time extended the possibility of the user to acquire remote sensing data for there research questions. Further, the fast acquisition and preprocessing of the remote sensing data enables a more interactive excess to environmental variables.
Fast access to environmental variables enables fast descriptive analyses, and the test of various hypothesises before the modelling process.
Thereby, the package shows the potential of simplified access to the capabilities of EE for the scientific work.


\section{Limits and problems of the current version of the earthEngineGrabR}

Although in many cases, the use of the earthEngineGrabR package offers significant advantages to the scientific work, the current version is still limited in many ways. 

\subsubsection{Vector data processing restriction}

Mainly, due to the current upload limit of the Fusion Table API, it is not possible to process vector data with more than 5000 features. This small size certainly restricts the application of the package and would make it uncomely for most scientific projects. 

\subsubsection{Limited number of available data products and their possible properties}

Furthermore, the choice of available data products and their properties in the earthEngineGrabR is still low. The package, for example, offers no product for temperature, climate or any vegetation indexes and the available products lack a necessary temporal resolution. For instance, since the smallest temporal interval is one year, it is not possible to request the precipitation or distance to surface water for a particular season. However, for the most ecological problems, the seasonality is of great importance.

\subsubsection{No control of projection}

Another problem is, that during the upload process all vector data is transformed to geographic reference system WGS84. That is that all the processing in EE is performed without a projection unless you call the WGS84 a projection. Therefore all projections of the original vector data are lost. The output of the \texttt{ee\_grab()} function does not reflect the projection of the imported vector data. The conversion to WGS84 is unproblematic as long as there is no calculation of areas. Since the spatial reducer of the earthEngineGrabR only allows simple statistics like mean, median, mode, min and max, there is no calculation of areas, and the conversion is harmless to the results of the analysis. However, in most cases, it would require a manual reprojection of the results by the user to combine the data collected by the earthEngineGrabR with data that is already at hand. Additional control of the projection would be helpful.

\subsubsection{Multiple dependencies, operating system interoperability, confusing authentication process}

The most challenging problem though is to get the earthEngineGrabR to work on all operating systems properly. This point is challenging because of the many requirements and dependencies of the package and the approach to invoke system calls. There are dependencies to R packages python libraries and external libraries such as GDAL, and there has to be a working python distribution on the system (see table \ref{dependencies}). If any of the requirements are not met, the package crashes. 
Further, the invoked system calls depend on specified paths as environmental variables on the users operating system. For example the commands \texttt{python}, \texttt{pip} or \texttt{ogr2ogr} are invoked with the \texttt{system()} function, if the commands can't be found, the execution fails. The problems could be solved by specifying the full path to the underlying programmes, but these again depend on the operating system and the Python distribution that is installed. In summary, the approach to use invoked system call via R's \texttt{system()} functions makes the package vulnerable to internal errors due to interoperability of different operating systems and local environments.

An additional difficulty is the confusing and extensive authentication process. While the Google Drive and Fusion Table API are accessed directly with R, the EE API and the GDAL driver for Fusion Tables are accessed with Python. In R the authentication protocol is managed by the httr R package and requires no manual copying and pasting of authorisation tokens. For the authorisation to the API's accessed from Python the copy and pasting of tokens are still necessary. 
Furthermore, the httr R package in its current implementation of the earthEngineGrabR works with access tokens, which need to be refreshed after approximately an hour while the authentication protocols managed with different Python libraries work with refresh tokens, which never expire and therefore only need one initial authorisation. While using the earthEngineGrabR, this results in regular interruptions where the user is asked to again log in to his Google Account. Although with an already logged in account, this is just one click with a mouse per hour, this can be problematic for unsupervised use of the package for instance on a  server. Therefore, although already strongly simplified, the current management of the dependencies and authentication protocols is still error-prone and requires too much activity on the user's side.

\section{Further development of the earthEngineGrabR}

Most of the shortcomings addressed in the last section can be rectified with the further development of the earthEngineGrabR package. 

The further development can be divided into the improvement of the interface between R and EE and the implementation and of additional features.

\subsection{Implementation of additional features}

Below, some additional extensions to the earthEngineGrabR are described that will rectify most of the addressed shortcomings.

\subsubsection{Add more data products}

The most important extension is the implementation of additional data products. All data products available within the EE public data catalogue can be considered (see table \ref{app:appendix2}). To provide data products covering weather and climate variables, the implementation of additional products based on ASTER (Advanced Spaceborne Thermal Emission and Reflection Radiometer) and MODIS would be reasonable. Furthermore, a data product to provide vegetation indices calculated form Sentinel or Landsat satellite imagery would be interestingg.

\subsubsection{Extend the properties of the data products}
To provide a smaller temporal resolution, the package could implement an additional monthInterval parameter, which filters for specific months. This would result in the possibility to specify year and month of the interval of interest and allow to acquire the chirps-precipitation and jrc-distance-to-surface-water product in a monthly resolution.
Furthermore, it would be reasonable to choose the spatial resolution for each data product separately and add control over the projection of the analysis. 
The projection could be controlled by using the target projection and send it as a string that specifies the EPSG (European Petroleum Survey Group - list of codes for geographic reference systems) to the EE servers and reprojects the requested data. Another option would be to control the projection explicitly with an additional argument.

\subsubsection{Internal iterations as a workaround for the vector data processing restriction}

To increase the overall file size and the number of features of the target that can be processed it is necessary to build a workaround for internal limitations of the Earth Engine API and the Fusion Table API. One is the upload limit for Fusion Tables, of around 5000 features at a time and another an export limit of Earth Engine of about 100 000 features at a time to Google Drive. The workaround for both limitations is to subdivide the file, iterate over the request of each subdivision and finally join the subdivision results back together. In the Fusion Table API, it is possible to upload vector data as a new Fusion Table or add to an existing one. Therefore, in the beginning, the file could be subdivided into chunks, which don't exceed 5000 features. While the first chunk is used to upload a new Fusion Table, all additional chunks can be added in an iteration process. This existing Fusion Table is used as the target in EE. If the export exceeds 100 000 features, it is again subdivided into multiple requests, downloaded separately and joined during the import process in R. This approach would enable the processing of considerably larger vector data and furthermore make use of a performance gain achieved by parallelisation and iteration. 

\subsubsection{Simplify the authentication process}

To simplify the authentication process, it would be relevant to replace the manually copy and pasting of the authorisation tokens with an automatic transfer. Next, all authorisation processes should work with a refresh token which only requires one initial authorisation. The produced credentials refresh automatically without the intervention of the user. To further shield the user from the authorisation process it would be reasonable to incorporate the \texttt{ee\_grab\_init()} inside the \texttt{ee\_grab()} function and run the initialisation if the credentials cannot be found. This way, if the user calls the \texttt{ee\_grab()} function the first time, \texttt{ee\_grab\_init()} gets called and triggers the authorisation process. 

\subsubsection{Add the possibility for the user to add and define new data products}

Finally, it would be necessary to consider a possibility to add new data products by the user. To achieve this either the earthEngineGrabR has to provide a function that works with all datasets on the EE Data Catalog or provide detailed documentation on how to create data products while the user acts like a coworker that incorporate changes to the earthEngineGrabR using the version control system of GitHub. This two examples indeed are extremes of two different designs of the earthEngineGrabR and a solution should make use of both directions. In the broader sense, it is the question of how to provide extensibility to users. It seems necessary that the package maintainer implements demanded features. However, to supply tools, that the users can build the required data products himself is probably superior to one individual being responsible for the implementation of every request.
Independently of the different approaches of how to provide extensibility, several implementations would undoubtedly simplify the integration of additional features and the collaboration with other users of the earthEngineGrabR package. The first is, to provide comprehensive documentation with additional sample sessions, vignettes or tutorials. Next, to implement tests in the development workflow and use them for Continuous Integration (CI). Discarding, of the improved stability of the package, testing and CI would improve the collaboration with co-workers and simplify the publication of the earthEngineGrabR. 

\subsection{Improve the integration of R and Python}

To improve the framework for the base functionality of the earthEngineGrabR package the interface of R and Python could be further developed. Instead of an interface depending on the console which invoiced system calls in the way described in the methods section the new published reticulate package of r-studio could be used (\cite{reticulate}). The use of reticulate would offer some significant benefits. The reticulate package provides the translation of R and Python data types. The direct translation of data from R to Python would overdue the use of a flat file connection to pass parameters or processing info. Further, reticulate contains a multitude of helper functions that ease the use of R in combination with Python (\texttt{py\_available()}, for instance, checks for a Python version on the system). While the execution of Pythons scripts with a console, require the Python code organised as scripts, with reticulate it's possible to run Python code directly in R and arrange the code in smaller, more flexible chunks, what is essential when it comes to tools that provide the option to expand the earthEngineGrabR with additional data products and functionalities. The use of the reticulate package also would simplify the installation of python dependencies, because they can be performed in R (\texttt{py\_install()} installs python libraries). Finlay, replace the invoiced system calls would solve the problem due to missing environmental variables. Because, most system call commands like \texttt{python} and \texttt{pip} could be replaced with functions of the reticulate package, the internal paths of these commands is irrelevant for the execution. The retuculate package would manage the execution and provide interoperability for all operating systems.

In summary, the reticulate package provide a more precise, less error-prone and more flexible interface of R and Python then the currently implemented use of system calls.

\section{Internal strengths, weaknesses and limitations of EE and their incorporation in the earthEngineGrabR}

Besides the discussed limitation, there are also limitations of EE, which in contrast to the limitations of the earthEngineGrabR, can't be avoided by further development of the package. 
These inherent limitations have a strong influence on the operations that can be performed efficiently with the package.
Accessory to the suggested improvement of the interface between R and Python and the
implementation of additional features, the limitations and strengths of EE pretend a direction to the further development of the package.

A reason for EE's performance is its ability to distribute and manage complex computations across many machines efficiently. There is an almost linear relationship of throughput (pixels/sec) with the number of machines (\cite{gorelick2017google}).
Although EE can execute and manage extensive computations, the underlying infrastructure consists of clusters of low-end servers, and there is a hard limit on the amount of data that can be brought to any individual server. The current Remote procedure call (RPC) and caching system limit the size of an object to 100 MB. An option to configure machines in EE is not available.

Users can only express computations by using the parallel processing primitives provided in the EE client library, and some non-parallelizable operations just cannot be performed efficiently in this environment.

\subsubsection{Strengths of EE}

The architecture of EE performers well on per-pixel and finite neighbourhood operations such as band-math, morphological operations, spectral unmixing, template matching and texture analysis and can easily combine such operations in long chains (hundreds to thousands). 

Furthermore, it is also highly optimised for statistical operations
that can be applied to a collection of images, such as computing statistics on a time-series stack of images. This way, the EE can easily handle very deep stacks (i.e., millions of images; trillions of pixels). 

\subsubsection{Weaknesses and limitations of EE}

It performs poorly for non-local operations in which a local value can be affected by arbitrarily distant inputs, such as watershed analysis or clustering algorithms. Further due to the caching limit of 100 MB, operations that require a significant amount of data allocatable at the same time, such as training many machine learning models or operations that involve long-running iterative processes, such as finite element analysis or agent-based models cannot be performed efficiently. 

Another significant limitation is the export limit of the EE to Google Drive.
The EE provides data export to Google Drive and Google Cloud Platform (GCP). While the export to GCP is fast and works with extensive datasets, the export to Google Drive is limited to 2 GB and proportionally slow. Due to the reason, that outside the USA the always free tier of the GCP is not available, the export to Google Drive is the only free option. Discarding the official limit of 2 GB, it has shown that keeping the size of the export small,  speeds up the process dramatically while export files larger 1 GB can result in hours of computation time. 

\subsection{The optimal application of EE in the earthEngineGrabR}

\subsubsection{Support the internal distribution mechanism of EE by processing the data products in parallel}

During the development of the earthEngineGrabR, the experience was repeatedly made, that requests of smaller magnitude are processed fast and immediately while requests exceeding a certain magnitude in data throughput, result in unforeseeable long data processing. Unfortunately, due to the reason, that the EE system hides nearly every aspect of the computation from the user, the magnitude generating this bottleneck is not obvious. Hence, avoiding the bottleneck saves hours of computation time and also enables processes that otherwise result in errors referring to computation timeout or user memory limit exceeding. For example, processing all available data products and joining them in one request, given a target shapefile of 10.000 features, takes more than 1 hour of computation, while iterating over the data products with one request each, is a matter of a few minutes. This insight is reflected in the internal design of the earthEnigneGrabR. In the \texttt{ee\_grab()} function, each data product is processed individually. Furthermore, this approach allows processing the data products in parallel. This way, data bottlenecks, resulting in long exporting and computation time and eventually timeout errors are avoided. The performance of the earthEngineGrabR depends on EE's ability to distribute computation by an internal parallelisation mechanism efficiently. Operations that can't be efficiently scaled result in unforeseeable long processes and error and slow down the computation. By requesting the data products individually and in parallel, instead of joining the inter-products in EE, the package supports the internal distribution and parallelisation mechanism of EE.

\subsubsection{Instead of acquiring Big Data, process Big Data and acquire the results}

The export limit of 2 GB from EE to Google Drive actively restricts the possible download size. To download large data sets under such conditions is time-consuming error-prone. Because the internal processes of EE are shielded from the user, there is no possibility to inform the user about the internal processing state of the computation. The user would have to wait unseeingly long without any response and in case of an internal error for nothing.
Therefore, if the task is to download large data sets, the search and order tools are the better choice.
Splitting the exported file into smaller chunks, indeed speed up the export and computation time but only partly solve the underlining problem.
While the data that can be processed inside EE can become remarkably large, the data that can be exported is proportionally small.
However, what makes EE unique are the available resources to process the data before exporting. 
To avoid the described export limit, instead of exporting the raw raster data, the processing resources are used to aggregate the data inside EE.  The aggregation inside EE dramatically reduces the file size and speeds up the export. 
With the earthEngineGrabR, it is not possible to acquire big geospatial data but to process big geospatial data and acquire the results.
Considering this, using vector data as the output of the \texttt{ee\_grab()} function is more suitable because it provides a more flexible data format, which can adapt the shape of any AOI. Furthermore, compared to raster, it is smaller in size and therefore can be downloaded faster avoiding the export limit of EE. 

The limitation and strengths of the earthEngineGrabR arise from the weakness and strengths of EE. Therefore, the generated data products should correspond to EE capabilities. For images, this results in the use of per-pixel and finite neighbourhood operations such as band-math, morphological operations, spectral unmixing, template matching and texture analysis.

To use the full potential of EE, the earthEngineGrabR has to provide comfortable and user-friendly access to the capabilities of EE while using EE's internal strengths to offer a variety of data products.

EE's internal strengths could be used to generate a number of processing intensive data products. For example to calculate different vegetation indices's out of satellite data. This product, would enable to choose a time interval in months, maximum cloud cover to filter the image collection, whether to use Landsat or Sentinel imagery and the index that is to be calculated. The product could generate NDVI, Normalised Difference Water Index (NDWI), Enhanced Vegetation Index (EVI) or Normalized Difference Built-up Index (NDBI) out of high-resolution satellite data.




